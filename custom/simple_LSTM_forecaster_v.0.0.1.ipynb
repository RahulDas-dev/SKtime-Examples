{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7e06648",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f8269b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Tuple\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef939883",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(linewidth=np.inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbc26fc",
   "metadata": {},
   "source": [
    "### Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43ff1a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape (120, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-02</th>\n",
       "      <td>2</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-03</th>\n",
       "      <td>3</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-04</th>\n",
       "      <td>4</td>\n",
       "      <td>4.1</td>\n",
       "      <td>4.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-05</th>\n",
       "      <td>5</td>\n",
       "      <td>5.1</td>\n",
       "      <td>5.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            v1   v2     t\n",
       "2023-01-01   1  1.1  1.01\n",
       "2023-01-02   2  2.1  2.01\n",
       "2023-01-03   3  3.1  3.01\n",
       "2023-01-04   4  4.1  4.01\n",
       "2023-01-05   5  5.1  5.01"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_sample = 120\n",
    "data = pd.DataFrame(\n",
    "    columns=[\"v1\", \"v2\", \"t\"],\n",
    "    index=pd.date_range(start=\"2023-01-01\", freq=\"D\", periods=n_sample),\n",
    ")\n",
    "data[\"v1\"] = np.arange(1, n_sample + 1)\n",
    "data[\"v2\"] = data[\"v1\"] + 0.1\n",
    "data[\"t\"] = data[\"v1\"] + 0.01\n",
    "\n",
    "print(f\"Data shape {data.shape}\")\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc48dce",
   "metadata": {},
   "source": [
    "### Test Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7aa64b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x shape (100, 2), train_y shape (100, 1)\n",
      "test_x shape  (20, 2),  test_y  shape (20, 1)\n"
     ]
    }
   ],
   "source": [
    "train_data = data.head(100)\n",
    "test_data = data.tail(20)\n",
    "train_x, train_y = train_data[[\"v1\", \"v2\"]].copy(deep=True), train_data[[\"t\"]].copy(\n",
    "    deep=True\n",
    ")\n",
    "test_x, test_y = test_data[[\"v1\", \"v2\"]].copy(deep=True), test_data[[\"t\"]].copy(\n",
    "    deep=True\n",
    ")\n",
    "\n",
    "print(f\"train_x shape {train_x.shape}, train_y shape {train_y.shape}\")\n",
    "print(f\"test_x shape  {test_x.shape},  test_y  shape {test_y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae25d3d",
   "metadata": {},
   "source": [
    "### SIMPLE LSTM DENSE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfe85826",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_model(shape: Tuple[int, int], n_unit: int = 64):\n",
    "    model = Sequential(\n",
    "        [\n",
    "            LSTM(units=n_unit, return_sequences=True, input_shape=shape, dropout=0.2),\n",
    "            LSTM(units=n_unit, return_sequences=True, dropout=0.2),\n",
    "            LSTM(units=n_unit, dropout=0.2),\n",
    "            Dense(units=1),\n",
    "        ],\n",
    "        name=\"LSTM_3_DENSE\",\n",
    "    )\n",
    "    model.compile(optimizer=\"adam\", loss=\"mse\", metrics=\"mae\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893ff0fc",
   "metadata": {},
   "source": [
    "### Forecaster Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15fbf92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LstmForecaster:\n",
    "    def __init__(self, window_len: int = 10, epoch: int = 25, batch_size: int = 64):\n",
    "        self.window_len = window_len\n",
    "        self.epoch = epoch\n",
    "        self.batch_size = batch_size\n",
    "        self.data_x_max, self.data_x_min = None, None\n",
    "        self.data_y_max, self.data_y_min = None, None\n",
    "        self.initial_state = None\n",
    "        self.forecaster = None\n",
    "\n",
    "    def minmax_scale_x(self, data_x: pd.DataFrame) -> pd.DataFrame:\n",
    "        return (data_x - self.data_x_min) / (self.data_x_max - self.data_x_min)\n",
    "\n",
    "    def minmax_scale_y(self, data_y: pd.Series) -> pd.Series:\n",
    "        return (data_y - self.data_y_min) / (self.data_y_max - self.data_y_min)\n",
    "\n",
    "    def inv_minmax_scale_y(self, data_y: pd.Series) -> pd.Series:\n",
    "        return data_y * (self.data_y_max - self.data_y_min) + self.data_y_min\n",
    "\n",
    "    def preprocess_data(\n",
    "        self, data_x: pd.DataFrame, data_y: pd.Series\n",
    "    ) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        x_data, y_data = [], []\n",
    "\n",
    "        data_size = data_x.shape[0]\n",
    "\n",
    "        self.data_x_max, self.data_x_min = data_x.max(), data_x.min()\n",
    "        self.data_y_max, self.data_y_min = data_y.max().item(), data_y.min().item()\n",
    "\n",
    "        x_scaled = self.minmax_scale_x(data_x)\n",
    "        y_scaled = self.minmax_scale_y(data_y)\n",
    "\n",
    "        # x_scaled = data_x\n",
    "        # y_scaled = data_y\n",
    "\n",
    "        xy_scaled = pd.concat([x_scaled, y_scaled], axis=1)\n",
    "\n",
    "        self.initial_state = xy_scaled.tail(self.window_len).to_numpy()[np.newaxis, :]\n",
    "\n",
    "        for i in range(self.window_len, data_size):\n",
    "            x_data.append(xy_scaled.iloc[i - self.window_len : i, :])\n",
    "            y_data.append(y_scaled.iloc[i, :])\n",
    "        return np.array(x_data, dtype=np.float64), np.array(y_data, dtype=np.float64)\n",
    "\n",
    "    def fit(self, X: pd.DataFrame, y: pd.Series):\n",
    "        x_data, y_data = self.preprocess_data(X, y)\n",
    "        self.forecaster = lstm_model(x_data.shape[1:])\n",
    "\n",
    "        self.forecaster.fit(\n",
    "            x_data, y_data, epochs=self.epoch, batch_size=self.batch_size, shuffle=False\n",
    "        )\n",
    "        return self\n",
    "\n",
    "    def predict(self, forecast_horizon: int, X: pd.DataFrame) -> np.ndarray:\n",
    "        y_predict = []\n",
    "        x_scaled = self.minmax_scale_x(X)\n",
    "        model_input = self.initial_state\n",
    "        for i in range(forecast_horizon):\n",
    "            predict_t = self.forecaster.predict(model_input, verbose=0)\n",
    "            y_predict.append(predict_t.flatten().item())\n",
    "            xhog = x_scaled.iloc[i, :].to_numpy()\n",
    "            new_test = np.hstack([xhog, predict_t.flatten()])\n",
    "            model_input_2d = model_input.reshape(self.window_len, -1)\n",
    "            model_input_2d = np.vstack([model_input_2d, new_test])[-self.window_len :]\n",
    "            model_input = model_input_2d[np.newaxis, :]\n",
    "        y_original_scale = self.inv_minmax_scale_y(np.array(y_predict))\n",
    "        return y_original_scale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a315de",
   "metadata": {},
   "source": [
    "### Training And Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54e27720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96, 4, 3) (96, 1) (1, 4, 3)\n",
      "[[[0.         0.         0.        ]\n",
      "  [0.01010101 0.01010101 0.01010101]\n",
      "  [0.02020202 0.02020202 0.02020202]\n",
      "  [0.03030303 0.03030303 0.03030303]]\n",
      "\n",
      " [[0.01010101 0.01010101 0.01010101]\n",
      "  [0.02020202 0.02020202 0.02020202]\n",
      "  [0.03030303 0.03030303 0.03030303]\n",
      "  [0.04040404 0.04040404 0.04040404]]\n",
      "\n",
      " [[0.02020202 0.02020202 0.02020202]\n",
      "  [0.03030303 0.03030303 0.03030303]\n",
      "  [0.04040404 0.04040404 0.04040404]\n",
      "  [0.05050505 0.05050505 0.05050505]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.93939394 0.93939394 0.93939394]\n",
      "  [0.94949495 0.94949495 0.94949495]\n",
      "  [0.95959596 0.95959596 0.95959596]\n",
      "  [0.96969697 0.96969697 0.96969697]]\n",
      "\n",
      " [[0.94949495 0.94949495 0.94949495]\n",
      "  [0.95959596 0.95959596 0.95959596]\n",
      "  [0.96969697 0.96969697 0.96969697]\n",
      "  [0.97979798 0.97979798 0.97979798]]\n",
      "\n",
      " [[0.95959596 0.95959596 0.95959596]\n",
      "  [0.96969697 0.96969697 0.96969697]\n",
      "  [0.97979798 0.97979798 0.97979798]\n",
      "  [0.98989899 0.98989899 0.98989899]]]\n",
      "[[0.04040404]\n",
      " [0.05050505]\n",
      " [0.06060606]\n",
      " [0.07070707]\n",
      " [0.08080808]\n",
      " [0.09090909]\n",
      " [0.1010101 ]\n",
      " [0.11111111]\n",
      " [0.12121212]\n",
      " [0.13131313]\n",
      " [0.14141414]\n",
      " [0.15151515]\n",
      " [0.16161616]\n",
      " [0.17171717]\n",
      " [0.18181818]\n",
      " [0.19191919]\n",
      " [0.2020202 ]\n",
      " [0.21212121]\n",
      " [0.22222222]\n",
      " [0.23232323]\n",
      " [0.24242424]\n",
      " [0.25252525]\n",
      " [0.26262626]\n",
      " [0.27272727]\n",
      " [0.28282828]\n",
      " [0.29292929]\n",
      " [0.3030303 ]\n",
      " [0.31313131]\n",
      " [0.32323232]\n",
      " [0.33333333]\n",
      " [0.34343434]\n",
      " [0.35353535]\n",
      " [0.36363636]\n",
      " [0.37373737]\n",
      " [0.38383838]\n",
      " [0.39393939]\n",
      " [0.4040404 ]\n",
      " [0.41414141]\n",
      " [0.42424242]\n",
      " [0.43434343]\n",
      " [0.44444444]\n",
      " [0.45454545]\n",
      " [0.46464646]\n",
      " [0.47474747]\n",
      " [0.48484848]\n",
      " [0.49494949]\n",
      " [0.50505051]\n",
      " [0.51515152]\n",
      " [0.52525253]\n",
      " [0.53535354]\n",
      " [0.54545455]\n",
      " [0.55555556]\n",
      " [0.56565657]\n",
      " [0.57575758]\n",
      " [0.58585859]\n",
      " [0.5959596 ]\n",
      " [0.60606061]\n",
      " [0.61616162]\n",
      " [0.62626263]\n",
      " [0.63636364]\n",
      " [0.64646465]\n",
      " [0.65656566]\n",
      " [0.66666667]\n",
      " [0.67676768]\n",
      " [0.68686869]\n",
      " [0.6969697 ]\n",
      " [0.70707071]\n",
      " [0.71717172]\n",
      " [0.72727273]\n",
      " [0.73737374]\n",
      " [0.74747475]\n",
      " [0.75757576]\n",
      " [0.76767677]\n",
      " [0.77777778]\n",
      " [0.78787879]\n",
      " [0.7979798 ]\n",
      " [0.80808081]\n",
      " [0.81818182]\n",
      " [0.82828283]\n",
      " [0.83838384]\n",
      " [0.84848485]\n",
      " [0.85858586]\n",
      " [0.86868687]\n",
      " [0.87878788]\n",
      " [0.88888889]\n",
      " [0.8989899 ]\n",
      " [0.90909091]\n",
      " [0.91919192]\n",
      " [0.92929293]\n",
      " [0.93939394]\n",
      " [0.94949495]\n",
      " [0.95959596]\n",
      " [0.96969697]\n",
      " [0.97979798]\n",
      " [0.98989899]\n",
      " [1.        ]]\n",
      "[[[0.96969697 0.96969697 0.96969697]\n",
      "  [0.97979798 0.97979798 0.97979798]\n",
      "  [0.98989899 0.98989899 0.98989899]\n",
      "  [1.         1.         1.        ]]]\n"
     ]
    }
   ],
   "source": [
    "fcaster = LstmForecaster(window_len=4, epoch=25)\n",
    "x_, y_ = fcaster.preprocess_data(train_x, train_y)\n",
    "\n",
    "print(x_.shape, y_.shape, fcaster.initial_state.shape)\n",
    "print(x_)\n",
    "print(y_)\n",
    "print(fcaster.initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7fc2baa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "2/2 [==============================] - 6s 26ms/step - loss: 0.3155 - mae: 0.5138\n",
      "Epoch 2/25\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1979 - mae: 0.4027\n",
      "Epoch 3/25\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0876 - mae: 0.2641\n",
      "Epoch 4/25\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0109 - mae: 0.0836\n",
      "Epoch 5/25\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0344 - mae: 0.1585\n",
      "Epoch 6/25\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0624 - mae: 0.2369\n",
      "Epoch 7/25\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0228 - mae: 0.1410\n",
      "Epoch 8/25\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0092 - mae: 0.0831\n",
      "Epoch 9/25\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0150 - mae: 0.0922\n",
      "Epoch 10/25\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0190 - mae: 0.1060\n",
      "Epoch 11/25\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0152 - mae: 0.0987\n",
      "Epoch 12/25\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0116 - mae: 0.0827\n",
      "Epoch 13/25\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0060 - mae: 0.0633\n",
      "Epoch 14/25\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0059 - mae: 0.0660\n",
      "Epoch 15/25\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0112 - mae: 0.0974\n",
      "Epoch 16/25\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0144 - mae: 0.1075\n",
      "Epoch 17/25\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0112 - mae: 0.0965\n",
      "Epoch 18/25\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0085 - mae: 0.0826\n",
      "Epoch 19/25\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0055 - mae: 0.0657\n",
      "Epoch 20/25\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0066 - mae: 0.0638\n",
      "Epoch 21/25\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0058 - mae: 0.0605\n",
      "Epoch 22/25\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0058 - mae: 0.0594\n",
      "Epoch 23/25\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0058 - mae: 0.0581\n",
      "Epoch 24/25\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0045 - mae: 0.0568\n",
      "Epoch 25/25\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0071 - mae: 0.0746\n"
     ]
    }
   ],
   "source": [
    "fcaster = LstmForecaster(window_len=10, epoch=25)\n",
    "fcaster.fit(train_x, train_y)\n",
    "\n",
    "y_pred = fcaster.predict(20, test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9da4bcf",
   "metadata": {},
   "source": [
    "### 20 Point forecasted results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a715228",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07c6a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.hstack([test_x.to_numpy(), y_pred.reshape(-1, 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b53e98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

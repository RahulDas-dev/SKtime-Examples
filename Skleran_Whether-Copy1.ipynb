{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "018eb51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.sanity import *\n",
    "\n",
    "from src.load_datasets import load_traffic_data\n",
    "\n",
    "from src.utils import (\n",
    "    show_dataset,\n",
    "    show_series,\n",
    "    plot_metrics,\n",
    "    test_train_split,\n",
    "    seperate_target,\n",
    "    plot_tf_training_history,\n",
    ")\n",
    "\n",
    "from src.features import (\n",
    "    create_lag_feature,\n",
    "    create_datetime_feature,\n",
    "    create_cyclic_feature,\n",
    "    create_window_feature,\n",
    "    cast_to_float,\n",
    ")\n",
    "\n",
    "from src.evaluation import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74c8ddbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(80)\n",
    "plt.style.use(\"seaborn-v0_8-darkgrid\")\n",
    "plt.rc(\n",
    "    \"axes\",\n",
    "    labelweight=\"bold\",\n",
    "    labelsize=\"large\",\n",
    "    titleweight=\"bold\",\n",
    "    titlesize=14,\n",
    "    titlepad=10,\n",
    ")\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94b475f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataframe shape (48204, 9)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48204 entries, 0 to 48203\n",
      "Data columns (total 9 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   holiday              48204 non-null  object \n",
      " 1   temp                 48204 non-null  float64\n",
      " 2   rain_1h              48204 non-null  float64\n",
      " 3   snow_1h              48204 non-null  float64\n",
      " 4   clouds_all           48204 non-null  int64  \n",
      " 5   weather_main         48204 non-null  object \n",
      " 6   weather_description  48204 non-null  object \n",
      " 7   date_time            48204 non-null  object \n",
      " 8   traffic_volume       48204 non-null  int64  \n",
      "dtypes: float64(3), int64(2), object(4)\n",
      "memory usage: 3.3+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>holiday</th>\n",
       "      <th>temp</th>\n",
       "      <th>rain_1h</th>\n",
       "      <th>snow_1h</th>\n",
       "      <th>clouds_all</th>\n",
       "      <th>weather_main</th>\n",
       "      <th>weather_description</th>\n",
       "      <th>date_time</th>\n",
       "      <th>traffic_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>288.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>scattered clouds</td>\n",
       "      <td>2012-10-02 09:00:00</td>\n",
       "      <td>5545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>289.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>broken clouds</td>\n",
       "      <td>2012-10-02 10:00:00</td>\n",
       "      <td>4516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>289.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>overcast clouds</td>\n",
       "      <td>2012-10-02 11:00:00</td>\n",
       "      <td>4767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>290.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>overcast clouds</td>\n",
       "      <td>2012-10-02 12:00:00</td>\n",
       "      <td>5026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>291.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>broken clouds</td>\n",
       "      <td>2012-10-02 13:00:00</td>\n",
       "      <td>4918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  holiday    temp  rain_1h  snow_1h  clouds_all weather_main  \\\n",
       "0    None  288.28      0.0      0.0          40       Clouds   \n",
       "1    None  289.36      0.0      0.0          75       Clouds   \n",
       "2    None  289.58      0.0      0.0          90       Clouds   \n",
       "3    None  290.13      0.0      0.0          90       Clouds   \n",
       "4    None  291.14      0.0      0.0          75       Clouds   \n",
       "\n",
       "  weather_description            date_time  traffic_volume  \n",
       "0    scattered clouds  2012-10-02 09:00:00            5545  \n",
       "1       broken clouds  2012-10-02 10:00:00            4516  \n",
       "2     overcast clouds  2012-10-02 11:00:00            4767  \n",
       "3     overcast clouds  2012-10-02 12:00:00            5026  \n",
       "4       broken clouds  2012-10-02 13:00:00            4918  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = load_traffic_data()\n",
    "print(f\"dataframe shape {dataframe.shape}\")\n",
    "print(dataframe.info())\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4abf914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select_column: DF Shape (48204, 7)\n",
      "format_datetime: DF Shape (48204, 7)\n",
      "set_index: DF Shape (48204, 6)\n",
      "interpolate_columns: DF Shape (48204, 6)\n",
      "dataframe shape (48204, 6)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 48204 entries, 2012-10-02 09:00:00 to 2018-09-30 23:00:00\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   holiday         48204 non-null  object \n",
      " 1   temp            48204 non-null  float64\n",
      " 2   rain_1h         48204 non-null  float64\n",
      " 3   snow_1h         48204 non-null  float64\n",
      " 4   clouds_all      48204 non-null  int64  \n",
      " 5   traffic_volume  48204 non-null  int64  \n",
      "dtypes: float64(3), int64(2), object(1)\n",
      "memory usage: 2.6+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>holiday</th>\n",
       "      <th>temp</th>\n",
       "      <th>rain_1h</th>\n",
       "      <th>snow_1h</th>\n",
       "      <th>clouds_all</th>\n",
       "      <th>traffic_volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-10-02 09:00:00</th>\n",
       "      <td>None</td>\n",
       "      <td>288.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>5545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-02 10:00:00</th>\n",
       "      <td>None</td>\n",
       "      <td>289.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75</td>\n",
       "      <td>4516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-02 11:00:00</th>\n",
       "      <td>None</td>\n",
       "      <td>289.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90</td>\n",
       "      <td>4767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-02 12:00:00</th>\n",
       "      <td>None</td>\n",
       "      <td>290.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90</td>\n",
       "      <td>5026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-02 13:00:00</th>\n",
       "      <td>None</td>\n",
       "      <td>291.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75</td>\n",
       "      <td>4918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    holiday    temp  rain_1h  snow_1h  clouds_all  \\\n",
       "date_time                                                           \n",
       "2012-10-02 09:00:00    None  288.28      0.0      0.0          40   \n",
       "2012-10-02 10:00:00    None  289.36      0.0      0.0          75   \n",
       "2012-10-02 11:00:00    None  289.58      0.0      0.0          90   \n",
       "2012-10-02 12:00:00    None  290.13      0.0      0.0          90   \n",
       "2012-10-02 13:00:00    None  291.14      0.0      0.0          75   \n",
       "\n",
       "                     traffic_volume  \n",
       "date_time                            \n",
       "2012-10-02 09:00:00            5545  \n",
       "2012-10-02 10:00:00            4516  \n",
       "2012-10-02 11:00:00            4767  \n",
       "2012-10-02 12:00:00            5026  \n",
       "2012-10-02 13:00:00            4918  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def encode_holiday(dataframe):\n",
    "    dataframe['holiday'] = dataframe['holiday'].apply(lambda x: 1 if x !='None' else 0)\n",
    "    return dataframe\n",
    "\n",
    "def fill_missing_date(dataframe, col, freq):\n",
    "    new_date_range = pd.date_range(dataframe.index.min(), dataframe.index.max(), freq=freq)\n",
    "    #dataframe.reset_index(drop=True, inplace=True)\n",
    "    dataframe_=dataframe.reindex(index=new_date_range, level=None)\n",
    "    return dataframe_\n",
    "    \n",
    "dataframe = (\n",
    "    load_traffic_data()\n",
    "    .pipe(select_column, cols=['date_time','holiday','temp','rain_1h','snow_1h','clouds_all','traffic_volume'])\n",
    "    .pipe(format_datetime, col=\"date_time\")\n",
    "    .pipe(set_index, col=\"date_time\")\n",
    "    #.pipe(fill_missing_date,col=\"date_time\", freq='H' )\n",
    "    #.pipe(encode_holiday)\n",
    "    .pipe(interpolate_column)\n",
    "    #.pipe(resample_Data, freq=\"3H\")\n",
    "    #.pipe(replace_null)\n",
    ")\n",
    "\n",
    "print(f\"dataframe shape {dataframe.shape}\")\n",
    "\n",
    "print(dataframe.info())\n",
    "\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "760c2eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rdas6\\AppData\\Local\\Temp\\ipykernel_17488\\1421243505.py:6: FutureWarning: reindexing with a non-unique Index is deprecated and will raise in a future version.\n",
      "  dataframe.reindex(new_date_range, fill_value=0)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reindex on an axis with duplicate labels",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#dataframe['date_time'].max(), dataframe['date_time'].min()\u001b[39;00m\n\u001b[0;32m      4\u001b[0m new_date_range \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mdate_range(dataframe\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mmin(), dataframe\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mmax(), freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mH\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m \u001b[43mdataframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_date_range\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataframe shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataframe\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\util\\_decorators.py:347\u001b[0m, in \u001b[0;36mrewrite_axis_style_signature.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Callable[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, Any]:\n\u001b[1;32m--> 347\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:5205\u001b[0m, in \u001b[0;36mDataFrame.reindex\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   5203\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maxis\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m   5204\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m-> 5205\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py:5289\u001b[0m, in \u001b[0;36mNDFrame.reindex\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   5286\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_multi(axes, copy, fill_value)\n\u001b[0;32m   5288\u001b[0m \u001b[38;5;66;03m# perform the reindex on the axes\u001b[39;00m\n\u001b[1;32m-> 5289\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reindex_axes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5290\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\n\u001b[0;32m   5291\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreindex\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:5004\u001b[0m, in \u001b[0;36mDataFrame._reindex_axes\u001b[1;34m(self, axes, level, limit, tolerance, method, fill_value, copy)\u001b[0m\n\u001b[0;32m   5002\u001b[0m index \u001b[38;5;241m=\u001b[39m axes[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   5003\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 5004\u001b[0m     frame \u001b[38;5;241m=\u001b[39m \u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reindex_index\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5005\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\n\u001b[0;32m   5006\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5008\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frame\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:5023\u001b[0m, in \u001b[0;36mDataFrame._reindex_index\u001b[1;34m(self, new_index, method, copy, level, fill_value, limit, tolerance)\u001b[0m\n\u001b[0;32m   5010\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_reindex_index\u001b[39m(\n\u001b[0;32m   5011\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5012\u001b[0m     new_index,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5018\u001b[0m     tolerance\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   5019\u001b[0m ):\n\u001b[0;32m   5020\u001b[0m     new_index, indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mreindex(\n\u001b[0;32m   5021\u001b[0m         new_index, method\u001b[38;5;241m=\u001b[39mmethod, level\u001b[38;5;241m=\u001b[39mlevel, limit\u001b[38;5;241m=\u001b[39mlimit, tolerance\u001b[38;5;241m=\u001b[39mtolerance\n\u001b[0;32m   5022\u001b[0m     )\n\u001b[1;32m-> 5023\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reindex_with_indexers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5024\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mnew_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5025\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5026\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5027\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_dups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   5028\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py:5355\u001b[0m, in \u001b[0;36mNDFrame._reindex_with_indexers\u001b[1;34m(self, reindexers, fill_value, copy, allow_dups)\u001b[0m\n\u001b[0;32m   5352\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m ensure_platform_int(indexer)\n\u001b[0;32m   5354\u001b[0m \u001b[38;5;66;03m# TODO: speed up on homogeneous DataFrame objects (see _reindex_multi)\u001b[39;00m\n\u001b[1;32m-> 5355\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[43mnew_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex_indexer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5358\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbaxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5359\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5360\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_dups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_dups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5361\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5362\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5363\u001b[0m \u001b[38;5;66;03m# If we've made a copy once, no need to make another one\u001b[39;00m\n\u001b[0;32m   5364\u001b[0m copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:737\u001b[0m, in \u001b[0;36mBaseBlockManager.reindex_indexer\u001b[1;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, only_slice, use_na_proxy)\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[38;5;66;03m# some axes don't allow reindexing with dups\u001b[39;00m\n\u001b[0;32m    736\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_dups:\n\u001b[1;32m--> 737\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maxes\u001b[49m\u001b[43m[\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_can_reindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    739\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim:\n\u001b[0;32m    740\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequested axis not found in manager\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:4316\u001b[0m, in \u001b[0;36mIndex._validate_can_reindex\u001b[1;34m(self, indexer)\u001b[0m\n\u001b[0;32m   4314\u001b[0m \u001b[38;5;66;03m# trying to reindex on an axis with duplicates\u001b[39;00m\n\u001b[0;32m   4315\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_as_unique \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[1;32m-> 4316\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot reindex on an axis with duplicate labels\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reindex on an axis with duplicate labels"
     ]
    }
   ],
   "source": [
    "#dataframe['date_time'].max(), dataframe['date_time'].min()\n",
    "\n",
    "\n",
    "new_date_range = pd.date_range(dataframe.index.min(), dataframe.index.max(), freq='H')\n",
    "\n",
    "dataframe.reindex(new_date_range, fill_value=0)\n",
    "\n",
    "print(f\"dataframe shape {dataframe.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a975f189",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_tange=pd.date_range(dataframe.index.min(), dataframe.index.max(), freq='H')\n",
    "dataframe_ = dataframe.reindex(dt_tange)\n",
    "print(f\"dataframe shape {dataframe_.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a530b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframe.index = pd.date_range(dataframe.index.min(), dataframe.index.max(), freq='H')\n",
    "\n",
    "#dataframe = dataframe.reindex(pd.date_range(dataframe.index.min(), dataframe.index.max(), freq='H'), fill_value=np.nan)\n",
    "#print(f\"dataframe shape {dataframe.shape}\")\n",
    "\n",
    "#dataframe.set_index('date_time',drop=True,inplace=True)\n",
    "#dataframe.index = pd.DatetimeIndex(dataframe.index)\n",
    "#idx = pd.date_range(d2, d, freq = \"D\")\n",
    "dataframe_ = dataframe.reindex(dt_tange,fill_value=np.nan)\n",
    "print(f\"dataframe shape {dataframe_.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5860d34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83aa05e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "holiday           52551\n",
       "temp              52551\n",
       "rain_1h           52551\n",
       "snow_1h           52551\n",
       "clouds_all        52551\n",
       "traffic_volume    52551\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcb6676",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_dataset(dataframe[:60], columns=[\"traffic_volume\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e46742",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_features = [\n",
    "    \"dayofweek\",\n",
    "    \"quarter\",\n",
    "    \"month\",\n",
    "    \"year\",\n",
    "    \"dayofyear\",\n",
    "    \"dayofmonth\",\n",
    "    \"weekofyear\",\n",
    "    \"dayofweek\",\n",
    "    \"is_week_end\",\n",
    "    \"is_week_day\",\n",
    "]\n",
    "cl_features = [\"day\", \"month\", \"year\"]\n",
    "lags = [1, 2]\n",
    "window_length = 3\n",
    "\n",
    "target_column = \"traffic_volume\"\n",
    "TEST_SIZE = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158f1b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = test_train_split(dataframe, test_size=TEST_SIZE)\n",
    "\n",
    "print(f\"Train Size after Test_Train Split: {train_data.shape}\")\n",
    "print(f\"Test  Size after Test_Train Split: {test_data.shape} \")\n",
    "\n",
    "build_features = lambda df: (\n",
    "    df.pipe(create_lag_feature, column=target_column, lags=lags)\n",
    "    .pipe(create_window_feature, column=target_column, window_len=window_length)\n",
    "    .pipe(create_datetime_feature, features_name=dt_features)\n",
    "    .pipe(create_cyclic_feature, features_name=cl_features)\n",
    "    .pipe(cast_to_float)\n",
    ")\n",
    "\n",
    "train_data_feat = build_features(train_data)\n",
    "test_data_feat = build_features(test_data)\n",
    "\n",
    "print(f\"train_data shape after Feature Union {train_data_feat.shape}\")\n",
    "print(f\"test_data shape after Feature Union {test_data_feat.shape}\")\n",
    "\n",
    "train_data_feat = train_data_feat[max(*lags) :]\n",
    "test_data_feat.fillna(method=\"backfill\", inplace=True)\n",
    "\n",
    "print(f\"train_data shape after Null Removal {train_data_feat.shape}\")\n",
    "print(f\"test_data shape after Null Removal {test_data_feat.shape}\")\n",
    "\n",
    "train_x, train_y = seperate_target(train_data_feat, target_column)\n",
    "test_x, test_y = seperate_target(test_data_feat, target_column)\n",
    "\n",
    "test_data_feat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4dbbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsDict = {}\n",
    "predictionsDF = pd.DataFrame(index=test_x.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2636f197",
   "metadata": {},
   "source": [
    "### KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bb3830",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "\n",
    "model_name = \"KNeighborsRegressor\"\n",
    "\n",
    "estimator_ = Pipeline(\n",
    "    [\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\n",
    "            \"regressor\",\n",
    "            KNeighborsRegressor(n_neighbors=2),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "param_grid = {\"regressor__n_neighbors\": [2, 3, 5, 7, 12, 15]}\n",
    "\n",
    "cross_validator = TimeSeriesSplit(n_splits=3)\n",
    "\n",
    "gsearch = GridSearchCV(\n",
    "    estimator=estimator_,\n",
    "    cv=cross_validator,\n",
    "    param_grid=param_grid,\n",
    "    refit=True,\n",
    "    verbose=3,\n",
    "    n_jobs=1,\n",
    ")\n",
    "\n",
    "gsearch.fit(train_x, train_y.to_numpy().flatten())\n",
    "\n",
    "print(gsearch.best_score_, gsearch.best_params_)\n",
    "\n",
    "model = gsearch.best_estimator_\n",
    "\n",
    "yhat = model.predict(test_x)\n",
    "\n",
    "resultsDict[model_name] = evaluate(test_y[target_column].to_numpy(), yhat)\n",
    "predictionsDF[model_name] = yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b8d2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_series(\n",
    "    [train_y[-90:], test_y, predictionsDF[model_name]],\n",
    "    labels=[\"train\", \"test\", \"predict\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64ce1be",
   "metadata": {},
   "source": [
    "### Ridge Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70d977a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import BayesianRidge\n",
    "\n",
    "model, yhat, model_name = None, None, None\n",
    "model_name = \"BayesianRidge\"\n",
    "\n",
    "model = Pipeline(\n",
    "    [\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\n",
    "            \"regressor\",\n",
    "            BayesianRidge(fit_intercept=True, verbose=True, compute_score=True),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "model.fit(train_x, train_y.to_numpy().flatten())\n",
    "yhat = model.predict(test_x)\n",
    "\n",
    "resultsDict[model_name] = evaluate(test_y[target_column].to_numpy(), yhat)\n",
    "predictionsDF[model_name] = yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da4b7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_series(\n",
    "    [train_y[-90:], test_y, predictionsDF[model_name]],\n",
    "    labels=[\"train\", \"test\", \"predict\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3ef52d",
   "metadata": {},
   "source": [
    "### LassoCV Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cb669c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "model, yhat, model_name = None, None, None\n",
    "\n",
    "model_name = \"LassoCV\"\n",
    "\n",
    "model = Pipeline(\n",
    "    [(\"scaler\", StandardScaler()), (\"regressor\", LassoCV(fit_intercept=True))]\n",
    ")\n",
    "\n",
    "model.fit(train_x, train_y.to_numpy().flatten())\n",
    "yhat = model.predict(test_x)\n",
    "\n",
    "resultsDict[model_name] = evaluate(test_y[target_column].to_numpy(), yhat)\n",
    "predictionsDF[model_name] = yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d459bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_series(\n",
    "    [train_y[-90:], test_y, predictionsDF[model_name]],\n",
    "    labels=[\"train\", \"test\", \"predict\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa99b0b",
   "metadata": {},
   "source": [
    "### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba5bc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "model, yhat, model_name = None, None, None\n",
    "\n",
    "model_name = \"RandomForestRegressor\"\n",
    "\n",
    "param_grid = {\n",
    "    #'bootstrap': [True,False],\n",
    "    \"max_depth\": [7, 8, 9],\n",
    "    \"min_samples_leaf\": [2, 3],\n",
    "    \"min_samples_split\": [7, 8],\n",
    "    \"n_estimators\": [300, 500, 600],\n",
    "}\n",
    "\n",
    "estimator_ = RandomForestRegressor(random_state=80)\n",
    "\n",
    "\n",
    "cross_validator = TimeSeriesSplit(n_splits=3)\n",
    "\n",
    "gsearch = GridSearchCV(\n",
    "    estimator=estimator_,\n",
    "    cv=cross_validator,\n",
    "    param_grid=param_grid,\n",
    "    refit=True,\n",
    "    verbose=3,\n",
    "    n_jobs=1,\n",
    ")\n",
    "\n",
    "# gsearch.fit(train_x_scaled, train_y.to_numpy().flatten())\n",
    "\n",
    "gsearch.fit(train_x, train_y.to_numpy().flatten())\n",
    "\n",
    "print(gsearch.best_score_, gsearch.best_params_)\n",
    "\n",
    "model = gsearch.best_estimator_\n",
    "\n",
    "yhat = model.predict(test_x)\n",
    "\n",
    "resultsDict[model_name] = evaluate(test_y[target_column].to_numpy(), yhat)\n",
    "predictionsDF[model_name] = yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4d5f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_series(\n",
    "    [train_y[-90:], test_y, predictionsDF[model_name]],\n",
    "    labels=[\"train\", \"test\", \"predict\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321719bb",
   "metadata": {},
   "source": [
    "### XGB Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd85146",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "model, yhat, model_name = None, None, None\n",
    "\n",
    "model_name = \"XGBRegressor\"\n",
    "\n",
    "model = xgb.XGBRegressor(\n",
    "    objective=\"reg:squarederror\",\n",
    "    n_estimators=1000,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.01,\n",
    "    tree_method=\"hist\",\n",
    "    early_stopping_rounds=20,\n",
    "    eval_metric=\"mae\",\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    train_x, train_y, eval_set=[(train_x, train_y), (test_x, test_y)], verbose=True\n",
    ")\n",
    "\n",
    "yhat = model.predict(test_x)\n",
    "\n",
    "resultsDict[model_name] = evaluate(test_y[target_column].to_numpy(), yhat)\n",
    "\n",
    "predictionsDF[model_name] = yhat\n",
    "\n",
    "# resultsDF.head()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "epochs = len(model.evals_result()[\"validation_0\"][\"mae\"])\n",
    "x_axis = range(0, epochs)\n",
    "ax.plot(x_axis, model.evals_result()[\"validation_0\"][\"mae\"], label=\"Train\")\n",
    "ax.plot(x_axis, model.evals_result()[\"validation_1\"][\"mae\"], label=\"Test\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470486b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_series(\n",
    "    [train_y[-90:], test_y, predictionsDF[model_name]],\n",
    "    labels=[\"train\", \"test\", \"predict\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d686e17",
   "metadata": {},
   "source": [
    "### LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a120101f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "model, yhat, model_name = None, None, None\n",
    "\n",
    "model_name = \"LGBMRegressor\"\n",
    "\n",
    "hyper_params = {\n",
    "    \"task\": \"train\",\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"objective\": \"regression\",\n",
    "    \"metric\": [\"mae\", \"l2\"],\n",
    "    \"learning_rate\": 0.005,\n",
    "    \"feature_fraction\": 0.9,\n",
    "    \"bagging_fraction\": 0.7,\n",
    "    \"bagging_freq\": 10,\n",
    "    \"verbose\": 0,\n",
    "    \"max_depth\": 8,\n",
    "    \"num_leaves\": 128,\n",
    "    \"max_bin\": 512,\n",
    "    \"num_iterations\": 10000,\n",
    "}\n",
    "\n",
    "model = lgb.LGBMRegressor()\n",
    "\n",
    "model.fit(\n",
    "    train_x,\n",
    "    train_y,\n",
    "    eval_set=[(train_x, train_y), (test_x, test_y)],\n",
    "    eval_metric=\"mae\",\n",
    "    early_stopping_rounds=100,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "\n",
    "yhat = model.predict(test_x, num_iteration=model.best_iteration_)\n",
    "\n",
    "resultsDict[model_name] = evaluate(test_y[target_column].to_numpy(), yhat)\n",
    "\n",
    "predictionsDF[model_name] = yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da45c421",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_series(\n",
    "    [train_y[-90:], test_y, predictionsDF[model_name]],\n",
    "    labels=[\"train\", \"test\", \"predict\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8977d4d7",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21a0a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import catboost\n",
    "\n",
    "model, yhat, model_name = None, None, None\n",
    "\n",
    "model_name = \"CatBoostRegressor\"\n",
    "\n",
    "model = catboost.CatBoostRegressor(learning_rate=0.1, depth=4, iterations=1000)\n",
    "\n",
    "train_pool = catboost.Pool(train_x, train_y)\n",
    "test_pool = catboost.Pool(test_x, test_y)\n",
    "\n",
    "grid = {\n",
    "    #    'learning_rate': [0.03, 0.1],\n",
    "    #    'depth':[4, 6, 10],\n",
    "    #    'l2_leaf_reg': [1, 3, 5, 7, 9]\n",
    "    \"l2_leaf_reg\": [3, 5]\n",
    "}\n",
    "\n",
    "grid_search_results = model.grid_search(\n",
    "    grid, train_pool, shuffle=False, verbose=3, refit=True, plot=True\n",
    ")\n",
    "\n",
    "\n",
    "print(grid_search_results[\"params\"])\n",
    "\n",
    "yhat = model.predict(test_x)\n",
    "\n",
    "resultsDict[model_name] = evaluate(test_y[target_column].to_numpy(), yhat)\n",
    "\n",
    "predictionsDF[model_name] = yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74a2aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_series(\n",
    "    [train_y[-90:], test_y, predictionsDF[model_name]],\n",
    "    labels=[\"train\", \"test\", \"predict\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd3d8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_search_results[\"params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3de5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "del (\n",
    "    train_data,\n",
    "    test_data,\n",
    "    train_data_feat,\n",
    "    test_data_feat,\n",
    "    train_x,\n",
    "    train_y,\n",
    "    test_x,\n",
    "    test_y,\n",
    "    train_pool,\n",
    "    test_pool,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fa68e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "model, yhat, model_name = None, None, None\n",
    "\n",
    "model_name = \"LSTM_Dense\"\n",
    "\n",
    "WINDOW_LEN = 24\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 100\n",
    "EPOCHS_ = 20\n",
    "\n",
    "train_data, test_data = test_train_split(dataframe, test_size=WINDOW_LEN + 30)\n",
    "\n",
    "build_features = lambda df: (\n",
    "    df.pipe(create_lag_feature, column=target_column, lags=lags)\n",
    "    .pipe(create_window_feature, column=target_column, window_len=window_length)\n",
    "    .pipe(create_datetime_feature, features_name=dt_features)\n",
    "    .pipe(create_cyclic_feature, features_name=cl_features)\n",
    "    .pipe(cast_to_float)\n",
    ")\n",
    "\n",
    "\n",
    "def window_data(X_data, y_data, window_len=7):\n",
    "    x_, y_ = [], []\n",
    "    for i in range(window_len - 1, len(X_data)):\n",
    "        x_.append(X_data[i - window_len + 1 : i + 1])\n",
    "        y_.append(y_data[i])\n",
    "    return np.array(x_), np.array(y_)\n",
    "\n",
    "\n",
    "train_data_feat = build_features(train_data)\n",
    "test_data_feat = build_features(test_data)\n",
    "\n",
    "train_data_feat = train_data_feat[max(*lags) :]\n",
    "test_data_feat.fillna(method=\"backfill\", inplace=True)\n",
    "\n",
    "\n",
    "train_x, train_y = seperate_target(train_data_feat, target_column)\n",
    "test_x, test_y = seperate_target(test_data_feat, target_column)\n",
    "\n",
    "scaler = StandardScaler().set_output(transform=\"pandas\")\n",
    "scaler.fit(train_x)\n",
    "\n",
    "train_x = scaler.transform(train_x)\n",
    "test_x = scaler.transform(test_x)\n",
    "\n",
    "x_window = np.concatenate([train_x, test_x])\n",
    "y_window = np.concatenate([train_y, test_y])\n",
    "\n",
    "\n",
    "x_window, y_window = window_data(x_window, y_window, window_len=WINDOW_LEN)\n",
    "\n",
    "x_train_data, x_test_data = x_window[: -len(test_x)], x_window[-len(test_x) :]\n",
    "y_train_data, y_test_data = y_window[: -len(test_x)], y_window[-len(test_x) :]\n",
    "\n",
    "train_data = (\n",
    "    tf.data.Dataset.from_tensor_slices((x_train_data, y_train_data))\n",
    "    .cache()\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .repeat()\n",
    ")\n",
    "\n",
    "\n",
    "test_data = (\n",
    "    tf.data.Dataset.from_tensor_slices((x_test_data, y_test_data))\n",
    "    .batch(BATCH_SIZE)\n",
    "    .repeat()\n",
    ")\n",
    "\n",
    "model = tf.keras.models.Sequential(\n",
    "    [\n",
    "        LSTM(128, input_shape=x_window.shape[-2:], dropout=0.0),\n",
    "        Dense(128),\n",
    "        Dense(128),\n",
    "        Dense(1),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"mse\", metrics=\"mae\")\n",
    "\n",
    "training_history = model.fit(\n",
    "    train_data,\n",
    "    epochs=EPOCHS_,\n",
    "    steps_per_epoch=200,\n",
    "    validation_data=test_data,\n",
    "    validation_steps=50,\n",
    ")\n",
    "yhat = model.predict(x_test_data)\n",
    "print(yhat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560d4089",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsDict[model_name] = evaluate(y_test_data.flatten(), yhat.flatten())\n",
    "\n",
    "predictionsDF[model_name] = yhat.flatten()[-len(predictionsDF.index) :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738bebe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tf_training_history(training_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2fd0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_series(\n",
    "    [train_y[-90:], test_y, predictionsDF[model_name]],\n",
    "    labels=[\"train\", \"test\", \"predict\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ceb6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsDF = pd.DataFrame.from_dict(resultsDict)\n",
    "resultsDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f820f80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsDF.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b3ed2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(resultsDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cbb3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsDF.T[\"dataset\"] = \"Weather\"\n",
    "resultsDF.T[\"Mode\"] = \"Singel_step\"\n",
    "\n",
    "resultsDF.T.to_csv(\"./Weather_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ed1ddf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
